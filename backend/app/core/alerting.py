"""
Log analysis and alerting infrastructure.

This module provides automated log analysis, pattern detection,
anomaly identification, and alerting capabilities for the application.
"""

import asyncio
import json
import re
from collections import defaultdict, deque
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Deque
from dataclasses import dataclass, field
from enum import Enum
import logging

from app.core.logging import get_context_logger
from app.core.metrics import get_metrics_collector, MetricsCollector


logger = get_context_logger(__name__)


class AlertSeverity(str, Enum):
    """Alert severity levels."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class AlertType(str, Enum):
    """Types of alerts that can be generated."""
    ERROR_RATE = "error_rate"
    API_FAILURE = "api_failure"
    SECURITY_EVENT = "security_event"
    PERFORMANCE_DEGRADATION = "performance_degradation"
    RATE_LIMIT_EXCEEDED = "rate_limit_exceeded"
    AUTHENTICATION_FAILURE = "authentication_failure"
    SYSTEM_HEALTH = "system_health"
    ANOMALY_DETECTION = "anomaly_detection"


@dataclass
class Alert:
    """An alert generated by the monitoring system."""
    id: str
    alert_type: AlertType
    severity: AlertSeverity
    title: str
    description: str
    timestamp: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)
    resolved: bool = False
    resolved_at: Optional[datetime] = None
    resolution_notes: Optional[str] = None


@dataclass
class AlertRule:
    """Configuration for an alert rule."""
    name: str
    alert_type: AlertType
    severity: AlertSeverity
    condition: Callable[[Dict[str, Any]], bool]
    description: str
    cooldown_minutes: int = 15  # Minimum time between alerts of same type
    enabled: bool = True


@dataclass
class LogPattern:
    """A pattern to detect in log messages."""
    name: str
    pattern: re.Pattern
    severity: AlertSeverity
    description: str
    alert_type: AlertType
    cooldown_minutes: int = 5


class LogAnalyzer:
    """
    Analyzes log entries for patterns, anomalies, and alert conditions.
    """
    
    def __init__(self):
        self.error_patterns = self._initialize_error_patterns()
        self.security_patterns = self._initialize_security_patterns()
        self.performance_patterns = self._initialize_performance_patterns()
        
        # Track recent log entries for analysis
        self.recent_logs: Deque[Dict[str, Any]] = deque(maxlen=1000)
        self.error_counts: Dict[str, int] = defaultdict(int)
        self.pattern_matches: Dict[str, List[datetime]] = defaultdict(list)
        
        logger.info("LogAnalyzer initialized with pattern detection")
    
    def _initialize_error_patterns(self) -> List[LogPattern]:
        """Initialize error detection patterns."""
        return [
            LogPattern(
                name="database_connection_error",
                pattern=re.compile(r"database.*connection.*failed|connection.*database.*error", re.IGNORECASE),
                severity=AlertSeverity.HIGH,
                description="Database connection failure detected",
                alert_type=AlertType.SYSTEM_HEALTH,
                cooldown_minutes=10
            ),
            LogPattern(
                name="trading212_api_error",
                pattern=re.compile(r"trading.*212.*api.*error|trading212.*request.*failed", re.IGNORECASE),
                severity=AlertSeverity.MEDIUM,
                description="Trading 212 API error detected",
                alert_type=AlertType.API_FAILURE,
                cooldown_minutes=5
            ),
            LogPattern(
                name="authentication_error",
                pattern=re.compile(r"authentication.*failed|invalid.*token|unauthorized", re.IGNORECASE),
                severity=AlertSeverity.MEDIUM,
                description="Authentication failure detected",
                alert_type=AlertType.AUTHENTICATION_FAILURE,
                cooldown_minutes=3
            ),
            LogPattern(
                name="rate_limit_error",
                pattern=re.compile(r"rate.*limit.*exceeded|too.*many.*requests", re.IGNORECASE),
                severity=AlertSeverity.MEDIUM,
                description="Rate limit exceeded",
                alert_type=AlertType.RATE_LIMIT_EXCEEDED,
                cooldown_minutes=15
            ),
            LogPattern(
                name="critical_error",
                pattern=re.compile(r"critical|fatal|emergency", re.IGNORECASE),
                severity=AlertSeverity.CRITICAL,
                description="Critical error detected",
                alert_type=AlertType.ERROR_RATE,
                cooldown_minutes=1
            )
        ]
    
    def _initialize_security_patterns(self) -> List[LogPattern]:
        """Initialize security event detection patterns."""
        return [
            LogPattern(
                name="suspicious_request",
                pattern=re.compile(r"suspicious.*request|potential.*attack|malicious.*activity", re.IGNORECASE),
                severity=AlertSeverity.HIGH,
                description="Suspicious request pattern detected",
                alert_type=AlertType.SECURITY_EVENT,
                cooldown_minutes=5
            ),
            LogPattern(
                name="sql_injection_attempt",
                pattern=re.compile(r"sql.*injection|union.*select|drop.*table", re.IGNORECASE),
                severity=AlertSeverity.HIGH,
                description="Potential SQL injection attempt",
                alert_type=AlertType.SECURITY_EVENT,
                cooldown_minutes=1
            ),
            LogPattern(
                name="brute_force_attempt",
                pattern=re.compile(r"multiple.*failed.*login|brute.*force|repeated.*authentication.*failure", re.IGNORECASE),
                severity=AlertSeverity.HIGH,
                description="Potential brute force attack",
                alert_type=AlertType.SECURITY_EVENT,
                cooldown_minutes=10
            )
        ]
    
    def _initialize_performance_patterns(self) -> List[LogPattern]:
        """Initialize performance issue detection patterns."""
        return [
            LogPattern(
                name="slow_request",
                pattern=re.compile(r"slow.*request|request.*timeout|response.*time.*exceeded", re.IGNORECASE),
                severity=AlertSeverity.MEDIUM,
                description="Slow request detected",
                alert_type=AlertType.PERFORMANCE_DEGRADATION,
                cooldown_minutes=10
            ),
            LogPattern(
                name="memory_warning",
                pattern=re.compile(r"memory.*warning|out.*of.*memory|memory.*usage.*high", re.IGNORECASE),
                severity=AlertSeverity.HIGH,
                description="Memory usage warning",
                alert_type=AlertType.SYSTEM_HEALTH,
                cooldown_minutes=15
            ),
            LogPattern(
                name="high_cpu_usage",
                pattern=re.compile(r"cpu.*usage.*high|high.*cpu.*load", re.IGNORECASE),
                severity=AlertSeverity.MEDIUM,
                description="High CPU usage detected",
                alert_type=AlertType.SYSTEM_HEALTH,
                cooldown_minutes=15
            )
        ]
    
    def analyze_log_entry(self, log_entry: Dict[str, Any]) -> List[Alert]:
        """
        Analyze a single log entry for patterns and generate alerts.
        
        Args:
            log_entry: Log entry dictionary
            
        Returns:
            List of alerts generated from this log entry
        """
        alerts = []
        self.recent_logs.append(log_entry)
        
        message = log_entry.get('message', '')
        level = log_entry.get('level', 'INFO')
        timestamp = datetime.fromisoformat(log_entry.get('timestamp', datetime.utcnow().isoformat()))
        
        # Check all pattern categories
        all_patterns = (
            self.error_patterns + 
            self.security_patterns + 
            self.performance_patterns
        )
        
        for pattern in all_patterns:
            if pattern.pattern.search(message):
                # Check cooldown period
                if self._is_pattern_in_cooldown(pattern.name, timestamp):
                    continue
                
                # Record pattern match
                self.pattern_matches[pattern.name].append(timestamp)
                
                # Generate alert
                alert = Alert(
                    id=f"{pattern.name}_{timestamp.strftime('%Y%m%d_%H%M%S')}",
                    alert_type=pattern.alert_type,
                    severity=pattern.severity,
                    title=f"{pattern.description}",
                    description=f"Pattern '{pattern.name}' detected in log: {message[:200]}...",
                    timestamp=timestamp,
                    metadata={
                        'pattern_name': pattern.name,
                        'log_level': level,
                        'log_message': message,
                        'log_entry': log_entry
                    }
                )
                alerts.append(alert)
                
                logger.warning(
                    f"Alert generated: {pattern.description}",
                    extra={
                        'alert_id': alert.id,
                        'alert_type': alert.alert_type.value,
                        'severity': alert.severity.value,
                        'pattern_name': pattern.name
                    }
                )
        
        return alerts
    
    def _is_pattern_in_cooldown(self, pattern_name: str, timestamp: datetime) -> bool:
        """Check if a pattern is in cooldown period."""
        if pattern_name not in self.pattern_matches:
            return False
        
        # Find the pattern configuration
        pattern_config = None
        all_patterns = (
            self.error_patterns + 
            self.security_patterns + 
            self.performance_patterns
        )
        
        for pattern in all_patterns:
            if pattern.name == pattern_name:
                pattern_config = pattern
                break
        
        if not pattern_config:
            return False
        
        # Check if last match was within cooldown period
        recent_matches = self.pattern_matches[pattern_name]
        if recent_matches:
            last_match = recent_matches[-1]
            cooldown_delta = timedelta(minutes=pattern_config.cooldown_minutes)
            if timestamp - last_match < cooldown_delta:
                return True
        
        return False
    
    def analyze_error_rate(self, time_window_minutes: int = 5) -> Optional[Alert]:
        """
        Analyze error rate over a time window.
        
        Args:
            time_window_minutes: Time window for analysis
            
        Returns:
            Alert if error rate is too high, None otherwise
        """
        now = datetime.utcnow()
        cutoff_time = now - timedelta(minutes=time_window_minutes)
        
        # Count errors in time window
        error_count = 0
        total_count = 0
        
        for log_entry in self.recent_logs:
            log_time = datetime.fromisoformat(log_entry.get('timestamp', now.isoformat()))
            if log_time >= cutoff_time:
                total_count += 1
                if log_entry.get('level') in ['ERROR', 'CRITICAL']:
                    error_count += 1
        
        if total_count == 0:
            return None
        
        error_rate = (error_count / total_count) * 100
        
        # Alert if error rate is above threshold
        if error_rate > 20 and error_count > 5:  # More than 20% errors and at least 5 errors
            return Alert(
                id=f"error_rate_{now.strftime('%Y%m%d_%H%M%S')}",
                alert_type=AlertType.ERROR_RATE,
                severity=AlertSeverity.HIGH,
                title="High Error Rate Detected",
                description=f"Error rate of {error_rate:.1f}% detected over {time_window_minutes} minutes ({error_count}/{total_count} logs)",
                timestamp=now,
                metadata={
                    'error_rate': error_rate,
                    'error_count': error_count,
                    'total_count': total_count,
                    'time_window_minutes': time_window_minutes
                }
            )
        
        return None
    
    def get_analysis_summary(self) -> Dict[str, Any]:
        """Get summary of log analysis results."""
        now = datetime.utcnow()
        last_hour = now - timedelta(hours=1)
        
        # Count recent pattern matches
        recent_patterns = {}
        for pattern_name, matches in self.pattern_matches.items():
            recent_matches = [m for m in matches if m >= last_hour]
            if recent_matches:
                recent_patterns[pattern_name] = len(recent_matches)
        
        # Count log levels in recent logs
        level_counts = defaultdict(int)
        for log_entry in self.recent_logs:
            log_time = datetime.fromisoformat(log_entry.get('timestamp', now.isoformat()))
            if log_time >= last_hour:
                level_counts[log_entry.get('level', 'UNKNOWN')] += 1
        
        return {
            'timestamp': now.isoformat(),
            'recent_logs_count': len(self.recent_logs),
            'recent_pattern_matches': recent_patterns,
            'log_level_counts_last_hour': dict(level_counts),
            'total_patterns_configured': len(
                self.error_patterns + 
                self.security_patterns + 
                self.performance_patterns
            )
        }


class AlertManager:
    """
    Manages alerts, alert rules, and notification delivery.
    """
    
    def __init__(self, metrics_collector: Optional[MetricsCollector] = None):
        self.metrics_collector = metrics_collector or get_metrics_collector()
        self.log_analyzer = LogAnalyzer()
        
        # Alert storage
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history: Deque[Alert] = deque(maxlen=1000)
        
        # Alert rules
        self.alert_rules = self._initialize_alert_rules()
        
        # Last alert times for cooldown management
        self.last_alert_times: Dict[str, datetime] = {}
        
        logger.info("AlertManager initialized")
    
    def _initialize_alert_rules(self) -> List[AlertRule]:
        """Initialize default alert rules."""
        return [
            AlertRule(
                name="high_error_rate",
                alert_type=AlertType.ERROR_RATE,
                severity=AlertSeverity.HIGH,
                condition=lambda metrics: (
                    metrics.get('error_rate', 0) > 10 and 
                    metrics.get('total_requests', 0) > 20
                ),
                description="Error rate exceeds 10% with significant traffic",
                cooldown_minutes=15
            ),
            AlertRule(
                name="trading212_api_unhealthy",
                alert_type=AlertType.API_FAILURE,
                severity=AlertSeverity.HIGH,
                condition=lambda metrics: (
                    metrics.get('trading212_health', {}).get('health_status') == 'unhealthy'
                ),
                description="Trading 212 API is unhealthy",
                cooldown_minutes=10
            ),
            AlertRule(
                name="consecutive_auth_failures",
                alert_type=AlertType.AUTHENTICATION_FAILURE,
                severity=AlertSeverity.MEDIUM,
                condition=lambda metrics: (
                    metrics.get('trading212_health', {}).get('authentication_failures', 0) > 5
                ),
                description="Multiple authentication failures detected",
                cooldown_minutes=5
            ),
            AlertRule(
                name="system_resource_warning",
                alert_type=AlertType.SYSTEM_HEALTH,
                severity=AlertSeverity.MEDIUM,
                condition=lambda metrics: (
                    metrics.get('system_health', {}).get('memory_usage_mb', 0) > 1000 or
                    metrics.get('system_health', {}).get('cpu_usage_percent', 0) > 80
                ),
                description="System resources under stress",
                cooldown_minutes=20
            )
        ]
    
    async def process_log_entry(self, log_entry: Dict[str, Any]) -> List[Alert]:
        """
        Process a log entry and generate alerts if needed.
        
        Args:
            log_entry: Log entry to analyze
            
        Returns:
            List of alerts generated
        """
        alerts = self.log_analyzer.analyze_log_entry(log_entry)
        
        for alert in alerts:
            await self._handle_alert(alert)
        
        return alerts
    
    async def check_metric_based_alerts(self) -> List[Alert]:
        """
        Check metric-based alert rules and generate alerts.
        
        Returns:
            List of alerts generated from metrics
        """
        alerts = []
        
        # Get current metrics
        health_report = self.metrics_collector.get_comprehensive_health_report()
        
        for rule in self.alert_rules:
            if not rule.enabled:
                continue
            
            # Check cooldown
            if self._is_rule_in_cooldown(rule.name):
                continue
            
            # Evaluate condition
            try:
                if rule.condition(health_report):
                    alert = Alert(
                        id=f"{rule.name}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}",
                        alert_type=rule.alert_type,
                        severity=rule.severity,
                        title=rule.description,
                        description=f"Alert rule '{rule.name}' triggered: {rule.description}",
                        timestamp=datetime.utcnow(),
                        metadata={
                            'rule_name': rule.name,
                            'metrics_snapshot': health_report
                        }
                    )
                    alerts.append(alert)
                    await self._handle_alert(alert)
                    
                    # Update cooldown
                    self.last_alert_times[rule.name] = datetime.utcnow()
                    
            except Exception as e:
                logger.error(
                    f"Error evaluating alert rule {rule.name}",
                    extra={
                        'rule_name': rule.name,
                        'error_type': type(e).__name__,
                        'error_message': str(e)
                    },
                    exc_info=True
                )
        
        return alerts
    
    def _is_rule_in_cooldown(self, rule_name: str) -> bool:
        """Check if an alert rule is in cooldown period."""
        if rule_name not in self.last_alert_times:
            return False
        
        rule = next((r for r in self.alert_rules if r.name == rule_name), None)
        if not rule:
            return False
        
        last_alert = self.last_alert_times[rule_name]
        cooldown_delta = timedelta(minutes=rule.cooldown_minutes)
        
        return datetime.utcnow() - last_alert < cooldown_delta
    
    async def _handle_alert(self, alert: Alert) -> None:
        """
        Handle a generated alert.
        
        Args:
            alert: Alert to handle
        """
        # Store alert
        self.active_alerts[alert.id] = alert
        self.alert_history.append(alert)
        
        # Log the alert
        logger.warning(
            f"Alert generated: {alert.title}",
            extra={
                'alert_id': alert.id,
                'alert_type': alert.alert_type.value,
                'severity': alert.severity.value,
                'description': alert.description
            }
        )
        
        # Record alert metrics
        await self.metrics_collector.record_error(
            error_type=f"alert_{alert.alert_type.value}",
            error_message=alert.description,
            component="alerting_system",
            severity=alert.severity.value,
            metadata=alert.metadata
        )
        
        # TODO: Implement notification delivery (email, webhook, etc.)
        await self._deliver_notification(alert)
    
    async def _deliver_notification(self, alert: Alert) -> None:
        """
        Deliver alert notification.
        
        Args:
            alert: Alert to deliver
        """
        # For now, just log the notification
        # In production, this would send emails, webhooks, etc.
        logger.info(
            f"Alert notification: {alert.severity.value.upper()} - {alert.title}",
            extra={
                'alert_id': alert.id,
                'notification_type': 'log_only',
                'alert_description': alert.description
            }
        )
    
    def resolve_alert(self, alert_id: str, resolution_notes: str = None) -> bool:
        """
        Resolve an active alert.
        
        Args:
            alert_id: ID of alert to resolve
            resolution_notes: Optional resolution notes
            
        Returns:
            True if alert was resolved, False if not found
        """
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.resolved = True
            alert.resolved_at = datetime.utcnow()
            alert.resolution_notes = resolution_notes
            
            # Remove from active alerts
            del self.active_alerts[alert_id]
            
            logger.info(
                f"Alert resolved: {alert.title}",
                extra={
                    'alert_id': alert_id,
                    'resolution_notes': resolution_notes
                }
            )
            
            return True
        
        return False
    
    def get_active_alerts(self) -> List[Alert]:
        """Get list of active (unresolved) alerts."""
        return list(self.active_alerts.values())
    
    def get_alert_history(self, limit: int = 100) -> List[Alert]:
        """Get alert history."""
        return list(self.alert_history)[-limit:]
    
    def get_alert_summary(self) -> Dict[str, Any]:
        """Get summary of alerting system status."""
        now = datetime.utcnow()
        last_hour = now - timedelta(hours=1)
        
        # Count alerts by severity in last hour
        recent_alerts = [
            alert for alert in self.alert_history 
            if alert.timestamp >= last_hour
        ]
        
        severity_counts = defaultdict(int)
        type_counts = defaultdict(int)
        
        for alert in recent_alerts:
            severity_counts[alert.severity.value] += 1
            type_counts[alert.alert_type.value] += 1
        
        return {
            'timestamp': now.isoformat(),
            'active_alerts_count': len(self.active_alerts),
            'total_alerts_last_hour': len(recent_alerts),
            'alerts_by_severity_last_hour': dict(severity_counts),
            'alerts_by_type_last_hour': dict(type_counts),
            'alert_rules_enabled': len([r for r in self.alert_rules if r.enabled]),
            'log_analysis_summary': self.log_analyzer.get_analysis_summary()
        }


# Global alert manager instance
_alert_manager: Optional[AlertManager] = None


def get_alert_manager() -> AlertManager:
    """Get the global alert manager instance."""
    global _alert_manager
    if _alert_manager is None:
        _alert_manager = AlertManager()
    return _alert_manager


def initialize_alert_manager(metrics_collector: Optional[MetricsCollector] = None) -> AlertManager:
    """Initialize the global alert manager."""
    global _alert_manager
    _alert_manager = AlertManager(metrics_collector)
    logger.info("Global alert manager initialized")
    return _alert_manager